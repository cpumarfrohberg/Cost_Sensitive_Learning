{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Class imbalance ⚖️ : Cost-sensitive Learning 🔨💰\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import where, unique, hstack, vstack \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## I. What is class imbalance and why could it be a problem for making predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if ratio majority class instances/minority class instances > 1 => \"class imbalance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking creditcard dataset (see kaggle: https://www.kaggle.com/c/GiveMeSomeCredit/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/creditcard.zip\", index_col=0)\n",
    "df[\"Class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284807, 27), (284807,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1] \n",
    "y = df[\"Class\"]\n",
    "X.shape, y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Because** of class imbalance in the dataset, **any model will be a lot more exposed to the majority class** => predictions will be biased towards predicting negative class for future instances\n",
    "- In fact, just by looking at the distribution, we could easily set up a **no skill model** generalizing that **there a NO fraud cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ...but what's the \"price\" we pay for using this (admittedly trivial) model? \n",
    "- in practice:\n",
    "    - consider the loss that one single, big fraud case can generate for a financial institution as a whole (e.g. thru so-called \"Loan Loss Provisions\" eating up profits)\n",
    "    - unfortunately, in the pandemic we have also learned first-hand what negative consequences a false prediction of **negatives** can have...\n",
    "\n",
    "#### So, \"no skill\" model doesn't seem very convincing...but let's give it a chance evaluating it with a formal metric such as \"accuracy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ accuracy = (TP+TN)/(TP+FP+TN+FN)$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.zeros(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accuracy actually indicates that \"no skill\"-model performs quite well! 🤔\n",
    "- => **underlying assumption** is that **number of correct predictions** should be **maximized**\n",
    "- => instead, you should evaluate binary classification models by **how well they distinguish between classes**, which lies at the center of \"ranking metrics\" (e.g. ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## II. How can we deal with the challenge of bias of our model towards majority class? \n",
    "## => apply cost-sensitive learning 🔨💰!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### \"Cost-sensitive learning (...) takes the costs of prediction errors (...) into account when training a machine learning model. (...) many conceptualizations and techniques developed and used for cost-sensitive learning can be adopted for imbalanced classification problems.\"  - Jason Brownlee "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Let's fit a simple **LogReg model** \n",
    "- with the following **cost function**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$ cost(ypred_{i}, y_{i}) = - (log(ypred_{i}) * y_{i} + log(1 - ypred_{i}) * (1 - y_{i}))$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X = X.copy() \n",
    "y = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((213605, 27), (71202, 27), (213605,), (71202,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y) # remember: you set \"stratify\" so that train data and labelled data have the same \"proportions\" re classes...\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "LogReg_unweighted = LogisticRegression(random_state=42, class_weight=None)  # instantiating model - default weighting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LogReg() can take several parameters, includig \"class_weight\" \n",
    "- if \"class_weight\" is not defined otherwise, **LogReg() will assume equally proportional penalties for errors**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg_unweighted.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LogReg_unweighted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[71052    27]\n",
      " [   49    74]]\n",
      "Area Under Curve: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Area Under Curve: {roc_auc_score(y_test, y_pred).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.16260162601627"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ratio_TP = 74/123*100\n",
    "Ratio_TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Intuition ROC \n",
    "- intuition ROC: a **curve** of **combinations** of **FP-rate** (x-axis) and **TP-rate** (y-axis) for a set of predictions by a classifier **for different thresholds**\n",
    "- note the **trade-off** between TP-rates and FP-rates (i.e. the **shape of the curve**)\n",
    "- helpful for evaluating **one model** (binary classification) **under different thresholds**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Intuition ROC AUC\n",
    "- intuition **AUC**: the **score** resulting from **area** below ROC\n",
    "- more precisely: probability, that the scores given by a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one\n",
    "- helpful for evaluating **more than one model to each other** (binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Enter the cost-sensitized LogReg classifier\n",
    "- LogReg algo can be modified to be better suited for imbalanced classification by means of introducing weights:\n",
    "    - the weighting can **penalize the model less** for **errors made on examples from the majority class** and penalize the model **more for errors made on examples from the minority class**.\n",
    "    - a **larger weight** value results in a **larger error calculation**, and in turn, **more update** to the model **coefficients** (and vice versa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ cost(ypred_{i}, y_{i}) = - (w_{0} * log(ypred_{i}) * y_{i} + w_{1} * log(1 - ypred_{i}) * (1 - y_{i}))$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "weights = {0:0.02, 1:0.98} # tuning weights... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **\"not all misclassification errors should be treated as equals\"**\n",
    "- if classifier has missed the minority class => multiply penalty by 0.998\n",
    "- if classifier has missed the majority class => multiply penalty by 0.002\n",
    "- note that the set weights correspond to the **inversed class ratio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "LogReg_weighted = LogisticRegression(random_state=42, class_weight=weights) # note explicit spec of \"weights\" param!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight={0: 0.02, 1: 0.98}, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg_weighted.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_hat_weighted = LogReg_weighted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[70644   435]\n",
      " [   27    96]]\n",
      "Area Under Curve: 0.89\n"
     ]
    }
   ],
   "source": [
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_hat_weighted)}\")\n",
    "print(f\"Area Under Curve: {roc_auc_score(y_test, y_hat_weighted).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.04878048780488"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ratio_TP = 96/123*100\n",
    "Ratio_TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "weights = {0:1, 1:10} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "LogReg_weighted = LogisticRegression(random_state=42, class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight={0: 1, 1: 10}, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg_weighted.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_hat_weighted = LogReg_weighted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[70984    95]\n",
      " [   30    93]]\n",
      "Area Under Curve: 0.88\n"
     ]
    }
   ],
   "source": [
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_hat_weighted)}\")\n",
    "print(f\"Area Under Curve: {roc_auc_score(y_test, y_hat_weighted).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.60975609756098"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ratio_TP = 93/123*100\n",
    "Ratio_TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "p = pd.DataFrame ({\n",
    "    \"Metric\": [\"AUC\",\"Ratio_TP\"],\n",
    "    \"Vanilla_LogReg\": [0.80, 0.60],\n",
    "    \"Cost_Weighted_LogReg\": [0.89, 0.78],\n",
    "    \"Cost_Weighted_OM_LogReg\": [0.88, 0.76]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vanilla_LogReg</th>\n",
       "      <th>Cost_Weighted_LogReg</th>\n",
       "      <th>Cost_Weighted_OM_LogReg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ratio_TP</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Vanilla_LogReg  Cost_Weighted_LogReg  Cost_Weighted_OM_LogReg\n",
       "Metric                                                                 \n",
       "AUC                  0.8                  0.89                     0.88\n",
       "Ratio_TP             0.6                  0.78                     0.76"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.set_index(\"Metric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, cost-sensitive learning leads to better results (based on ROC AUC)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "6068792312ae472a9ee8f502efbbc8d064b51452bd6869953f70e7706460b5ea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('SPICED_trial_lecture': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
